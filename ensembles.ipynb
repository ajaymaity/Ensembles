{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from: https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29 (with minor changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Ensemble Techniques\n",
    "### Max Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and define train and test\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "test_ratio = 0.3\n",
    "instances = x.shape[0]\n",
    "test_instances = int(instances * test_ratio)\n",
    "\n",
    "index_arr = np.arange(instances)\n",
    "np.random.shuffle(index_arr)\n",
    "\n",
    "random_test_inst = index_arr[:test_instances]\n",
    "random_train_inst = index_arr[test_instances:]\n",
    "\n",
    "x_train = x[random_train_inst]\n",
    "y_train = y[random_train_inst]\n",
    "x_test = x[random_test_inst]\n",
    "y_test = y[random_test_inst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Train models and perform prediction\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1=model1.predict(x_test)\n",
    "pred2=model2.predict(x_test)\n",
    "pred3=model3.predict(x_test)\n",
    "\n",
    "# Max Voting Ensemble\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(x_test)):\n",
    "    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_ens = accuracy_score(y_test, final_pred)\n",
    "print(accuracy_ens)\n",
    "\n",
    "accuracy_model1 = accuracy_score(y_test, pred1)\n",
    "print(accuracy_model1)\n",
    "\n",
    "accuracy_model2 = accuracy_score(y_test, pred2)\n",
    "print(accuracy_model2)\n",
    "\n",
    "accuracy_model3 = accuracy_score(y_test, pred3)\n",
    "print(accuracy_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 'VotingClassifier' module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay2\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(x_test)\n",
    "pred2=model2.predict_proba(x_test)\n",
    "pred3=model3.predict_proba(x_test)\n",
    "\n",
    "finalpred=(pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(x_test)\n",
    "pred2=model2.predict_proba(x_test)\n",
    "pred3=model3.predict_proba(x_test)\n",
    "\n",
    "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ensemble Techniques\n",
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def Stacking(model, train, y, test, n_fold):\n",
    "   folds = StratifiedKFold(n_splits=n_fold, random_state=1)\n",
    "   test_pred = np.empty((0, 1), float)\n",
    "   train_pred = np.empty((0, 1), float)\n",
    "\n",
    "   for train_indices, val_indices in folds.split(train, y):\n",
    "      x_train, x_val = train[train_indices], train[val_indices]\n",
    "      y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "      model.fit(X=x_train, y=y_train)\n",
    "      train_pred = np.append(train_pred, model.predict(x_val))\n",
    "   \n",
    "   test_pred = np.append(test_pred, model.predict(test))\n",
    "   return test_pred.reshape(-1,1), train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "test_pred1, train_pred1 = Stacking(model=model1, n_fold=10, train=x_train, test=x_test, y=y_train)\n",
    "\n",
    "train_pred1 = pd.DataFrame(train_pred1)\n",
    "test_pred1 = pd.DataFrame(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
    "\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222222222222222"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model on the predictions of DT and KNN\n",
    "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df,y_train)\n",
    "model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 4) (74,) (31, 4) (31,) (45, 4) (45,)\n"
     ]
    }
   ],
   "source": [
    "val_ratio = 0.3\n",
    "instances = x_train.shape[0]\n",
    "val_instances = int(instances * val_ratio)\n",
    "\n",
    "index_arr = np.arange(instances)\n",
    "np.random.shuffle(index_arr)\n",
    "\n",
    "random_val_inst = index_arr[:val_instances]\n",
    "random_train_inst = index_arr[val_instances:]\n",
    "\n",
    "x_train_new = x_train[random_train_inst]\n",
    "y_train_new = y_train[random_train_inst]\n",
    "x_val = x_train[random_val_inst]\n",
    "y_val = y_train[random_val_inst]\n",
    "x_train = x_train_new\n",
    "y_train = y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model1.fit(x_train, y_train)\n",
    "val_pred1=model1.predict(x_val)\n",
    "test_pred1=model1.predict(x_test)\n",
    "val_pred1=pd.DataFrame(val_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(x_train,y_train)\n",
    "val_pred2=model2.predict(x_val)\n",
    "test_pred2=model2.predict(x_test)\n",
    "val_pred2=pd.DataFrame(val_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 6) (185,)\n"
     ]
    }
   ],
   "source": [
    "x_val = pd.DataFrame(x_val)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "df_val=pd.concat([x_val, val_pred1,val_pred2],axis=1)\n",
    "df_test=pd.concat([x_test, test_pred1,test_pred2],axis=1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(df_val,y_val)\n",
    "model.score(df_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#reading the dataset\n",
    "df=pd.read_csv(\"data/train_u6lujuX_CVtuZ9i.csv\")\n",
    "\n",
    "#filling missing values\n",
    "df['Gender'].fillna('Male', inplace=True)\n",
    "df['Married'].fillna('No', inplace=True)\n",
    "df['Dependents'].fillna('0', inplace=True)\n",
    "df['Self_Employed'].fillna('No', inplace=True)\n",
    "df['LoanAmount'].fillna(0, inplace=True)\n",
    "df['Loan_Amount_Term'].fillna(0, inplace=True)\n",
    "df['Credit_History'].fillna(0, inplace=True)\n",
    "\n",
    "df.drop('Loan_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 20) (429,) (185, 20) (185,)\n"
     ]
    }
   ],
   "source": [
    "#split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=0)\n",
    "\n",
    "x_train=train.drop('Loan_Status',axis=1)\n",
    "y_train=train['Loan_Status']\n",
    "\n",
    "x_test=test.drop('Loan_Status',axis=1)\n",
    "y_test=test['Loan_Status']\n",
    "\n",
    "#create dummies\n",
    "x_train=pd.get_dummies(x_train)\n",
    "x_test=pd.get_dummies(x_test)\n",
    "\n",
    "y_train = np.where(y_train=='Y', 1, 0)\n",
    "y_test = np.where(y_test=='Y', 1, 0)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513513513513513"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04062042727538784"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "model = BaggingRegressor(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test) # Score is not a proper metric as it calculates accuracy. RMSE should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7297297297297297"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model= RandomForestClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplicantIncome 0.20619915810055023\n",
      "CoapplicantIncome 0.14023302896973128\n",
      "Credit_History 0.14424378147061429\n",
      "Dependents_0 0.022812759081104066\n",
      "Dependents_1 0.011017420432025693\n",
      "Dependents_2 0.015626281908906588\n",
      "Dependents_3+ 0.015899769762191936\n",
      "Education_Graduate 0.016446809179378307\n",
      "Education_Not Graduate 0.020918235446052865\n",
      "Gender_Female 0.013506339083008958\n",
      "Gender_Male 0.009643762358149385\n",
      "LoanAmount 0.17681775377669445\n",
      "Loan_Amount_Term 0.039840002006671565\n",
      "Married_No 0.0170681424311086\n",
      "Married_Yes 0.028655495091033933\n",
      "Property_Area_Rural 0.03288496917994647\n",
      "Property_Area_Semiurban 0.022161855006493036\n",
      "Property_Area_Urban 0.026975470377103638\n",
      "Self_Employed_No 0.021349307176709527\n",
      "Self_Employed_Yes 0.017699659162525166\n"
     ]
    }
   ],
   "source": [
    "for i, j in sorted(zip(x_train.columns, model.feature_importances_)):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06308896693005561"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model= RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test) # RMSE should be used here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
